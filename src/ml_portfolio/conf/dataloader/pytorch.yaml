# PyTorchDataLoader Configuration
# Mini-batch iteration with PyTorch's native DataLoader
# Perfect for deep learning models (LSTM, Transformer, etc.)

_target_: ml_portfolio.data.loaders.PyTorchDataLoader

# Batch configuration
batch_size: 64
shuffle: true
drop_last: false  # Whether to drop last incomplete batch

# Multi-process data loading
num_workers: 0  # Set to 2-4 for faster loading (requires PyTorch)

# GPU optimization
pin_memory: false  # Set to true if using GPU for faster data transfer

# dataset parameter will be passed by train.py when instantiating
