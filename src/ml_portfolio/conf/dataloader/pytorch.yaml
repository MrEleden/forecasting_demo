# PyTorchDataLoader Configuration
# Mini-batch iteration with PyTorch's native DataLoader
# Perfect for deep learning models (LSTM, Transformer, etc.)

_target_: ml_portfolio.data.loaders.PyTorchDataLoader

# Batch configuration
batch_size: 512  # High-performance: larger batches for RTX 4080 SUPER (16GB VRAM)
shuffle: true
drop_last: false  # Whether to drop last incomplete batch

# Multi-process data loading
num_workers: 0  # Increased parallel CPU workers for better throughput

# GPU optimization
pin_memory: true  # Faster CPU-to-GPU data transfer

# dataset parameter will be passed by train.py when instantiating
