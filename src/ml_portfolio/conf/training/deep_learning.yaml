# Deep learning training configuration
# Suitable for PyTorch models (LSTM, Transformer, etc.)

max_epochs: 100  # Multiple epochs for iterative training
early_stopping: true  # Enable early stopping
patience: 10  # Stop if no improvement for 10 epochs
min_delta: 0.0001  # Minimum improvement threshold
monitor_metric: val_loss  # Metric to monitor for early stopping
verbose: true  # Print training progress
save_checkpoints: true  # Save model checkpoints
checkpoint_dir: models/checkpoints  # Directory for saving checkpoints