# ==============================================================================
# Main Configuration for ML Portfolio Training Pipeline
# ==============================================================================
#
# This config follows ML Engineering best practices:
# - Data leakage prevention (fit on train, transform all)
# - Test set isolation (never touched until final evaluation)
# - Config-driven design (Hydra)
# - Reproducibility (seeds, logging)
#
# Usage:
#   python src/ml_portfolio/training/train.py
#   python src/ml_portfolio/training/train.py model=xgboost
#   python src/ml_portfolio/training/train.py -m model=lightgbm,xgboost
#
# ==============================================================================

defaults:
  - dataset_factory: default
  - feature_engineering: none
  - model: random_forest
  - metrics: default
  - _self_

# ==============================================================================
# EXPERIMENT SETTINGS
# ==============================================================================

# Experiment identification
experiment_name: ml_portfolio_forecasting
dataset_name: default
run_name: null  # Auto-generated if null (format: {model}_{timestamp})

# Random seed for reproducibility
seed: 42

# ==============================================================================
# LOGGING CONFIGURATION
# ==============================================================================

log_level: INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
verbose: true

# ==============================================================================
# TRACKING AND OPTIMIZATION
# ==============================================================================

# MLflow experiment tracking
use_mlflow: false

# Optuna hyperparameter optimization
use_optuna: false
primary_metric: MAPE  # Metric to optimize (always on validation set)
minimize: true  # Whether to minimize the metric (true for MAPE/RMSE/MAE)

# ==============================================================================
# MODEL PERSISTENCE
# ==============================================================================

# Checkpointing
save_checkpoints: true
checkpoint_dir: null  # Auto-generated in outputs/ if null

# ==============================================================================
# TRAINING SETTINGS
# ==============================================================================

# Early stopping (for iterative models)
early_stopping_patience: null  # Set per model if needed
early_stopping_min_delta: 0.001

# Validation frequency
validate_every_n_epochs: 1

# ==============================================================================
# HYDRA CONFIGURATION
# ==============================================================================

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: outputs/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
