# Main configuration file for ML Portfolio training
# This serves as the base configuration for all training runs

defaults:
  - dataset_factory: default  # Use DatasetFactory for creating train/val/test splits
  - model: random_forest  # Statistical or ML models
  - dataloader: simple  # DataLoader configuration (simple, pytorch)
  - training: default  # Training configuration (default, deep_learning, statistical)
  - optimizer: null  # For deep learning models (adam, adamw, sgd)
  - scheduler: null  # LR scheduler for deep learning (step_lr, cosine, plateau)
  - metrics: default
  - _self_

# Optimizer and scheduler are optional (only for PyTorch models)
# For sklearn models: set to null
# For PyTorch models: specify optimizer=adam scheduler=step_lr

# Logging and output
logging:
  log_dir: outputs
  experiment_name: experiment
  save_checkpoints: true
  checkpoint_dir: models/checkpoints

# Hydra configuration
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: outputs/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
