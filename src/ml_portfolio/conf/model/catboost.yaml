# @package _global_

# CatBoost Model Configuration
# Gradient boosting with categorical feature support
# Often outperforms XGBoost/LightGBM on retail data

defaults:
  - /dataloader: simple
  - /engine: statistical

model:
  # Model instantiation
  _target_: ml_portfolio.models.statistical.catboost.CatBoostForecaster

  # Core parameters
  iterations: 500
  learning_rate: 0.05
  depth: 8

  # Regularization
  l2_leaf_reg: 3.0  # L2 regularization
  bagging_temperature: 1.0  # Randomness for bagging
  random_strength: 1.0  # Randomness for score calculation

  # Sampling
  subsample: 0.8

  # Performance
  thread_count: 4  # Limit threads to avoid memory issues during optimization
  random_seed: 42
  verbose: 0  # 0=silent, 1=info
  task_type: CPU  # Explicitly use CPU to avoid GPU conflicts

  # Early stopping (configured with validation set)
  early_stopping_rounds: 50

  # Loss function
  loss_function: RMSE  # RMSE, MAE, MAPE, Quantile, etc.
